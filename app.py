import streamlit as st
from transformers import pipeline
from PIL import Image
from deep_translator import GoogleTranslator
import pandas as pd
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.ensemble import RandomForestClassifier
import tempfile

# ==============================
# âš™ï¸ ConfiguraÃ§Ã£o inicial
# ==============================
st.set_page_config(page_title="AI Universal Studio", page_icon="ğŸ§ ", layout="wide")
st.title("ğŸ§  AI Universal Studio")
st.write("DemonstraÃ§Ã£o de um sistema de IA que aprende a partir de **imagens**, **textos** e **voz** (via upload) para gerar **previsÃµes inteligentes** âš¡")

# ==============================
# ğŸ§© Modelos
# ==============================
@st.cache_resource
def load_caption_model():
    return pipeline("image-to-text", model="Salesforce/blip-image-captioning-base")

@st.cache_resource
def load_audio_model():
    return pipeline("automatic-speech-recognition", model="openai/whisper-base")

captioner = load_caption_model()
asr = load_audio_model()

# ==============================
# ğŸ” SessÃ£o compartilhada
# ==============================
for var, default in {
    "keywords": [],
    "categories": [],
    "modelo": None,
    "vectorizer": None
}.items():
    if var not in st.session_state:
        st.session_state[var] = default

# ==============================
# ğŸ§­ Abas
# ==============================
aba = st.tabs([
    "ğŸ§© Etapa 1 - Base de Treinamento",
    "âš™ï¸ Etapa 2 - Treinar Modelo",
    "ğŸ”® Etapa 3 - Fazer PrevisÃ£o"
])

# ======================================================
# 1ï¸âƒ£ ETAPA 1 â€“ BASE DE TREINAMENTO
# ======================================================
with aba[0]:
    st.header("ğŸ§© Etapa 1 â€“ Criar base de aprendizado (Palavras + Categorias)")
    st.write("Adicione atÃ© **3 exemplos de texto** para ensinar a IA o que significa cada categoria (Baixo, Moderado, Alto risco).")

    entradas = []
    for i in range(3):
        col1, col2 = st.columns([3, 1])
        palavras = col1.text_input(f"ğŸ“ Exemplo {i+1} (texto ou frase):", key=f"texto_{i}")
        categoria = col2.selectbox(
            f"ğŸ¯ Categoria {i+1}:",
            ["Baixo", "Moderado", "Alto"],
            index=1,
            key=f"cat_{i}"
        )
        if palavras:
            entradas.append({"texto": palavras, "categoria": categoria})

    if entradas and st.button("ğŸ’¾ Salvar base de aprendizado"):
        st.session_state.keywords = [e["texto"] for e in entradas]
        st.session_state.categories = [e["categoria"] for e in entradas]
        st.success("âœ… Base de aprendizado salva com sucesso!")
        st.dataframe(pd.DataFrame(entradas))

# ======================================================
# 2ï¸âƒ£ ETAPA 2 â€“ TREINAR MODELO
# ======================================================
with aba[1]:
    st.header("âš™ï¸ Etapa 2 â€“ Treinar modelo com base na base de aprendizado")

    if not st.session_state.keywords or not st.session_state.categories:
        st.warning("âš ï¸ Nenhum dado de aprendizado. VÃ¡ para a Etapa 1 primeiro.")
    else:
        if st.button("ğŸš€ Treinar modelo agora"):
            vectorizer = CountVectorizer()
            X = vectorizer.fit_transform(st.session_state.keywords)
            y = st.session_state.categories
            modelo = RandomForestClassifier()
            modelo.fit(X, y)
            st.session_state.vectorizer = vectorizer
            st.session_state.modelo = modelo
            st.success("âœ… Modelo treinado com sucesso! VÃ¡ para a Etapa 3 para prever.")

        if st.session_state.modelo and st.session_state.vectorizer:
            st.info("âœ… Modelo jÃ¡ treinado! VocÃª pode ir para a Etapa 3.")

            # ======================================================
            # ğŸ§  Mostrar palavras-chave aprendidas pelo modelo
            # ======================================================
            st.subheader("ğŸ§  Palavras-chave aprendidas pelo modelo")

            vocab = st.session_state.vectorizer.get_feature_names_out()
            st.write(f"Total de **{len(vocab)}** palavras aprendidas.")
            st.write(", ".join(sorted(vocab)))

            # Mostrar por categoria
            df_treino = pd.DataFrame({
                "texto": st.session_state.keywords,
                "categoria": st.session_state.categories
            })

            st.markdown("### ğŸ“š Palavras aprendidas por categoria:")

            tokenizer = st.session_state.vectorizer.build_analyzer()
            for categoria in df_treino["categoria"].unique():
                textos_cat = " ".join(df_treino[df_treino["categoria"] == categoria]["texto"]).lower()
                palavras_cat = set(tokenizer(textos_cat))
                st.markdown(f"**{categoria}:** " + ", ".join(sorted(palavras_cat)))

# ======================================================
# 3ï¸âƒ£ ETAPA 3 â€“ PREVISÃƒO (Imagem + Texto + Ãudio)
# ======================================================
with aba[2]:
    st.header("ğŸ”® Etapa 3 â€“ Fazer previsÃ£o com novos dados (imagem + texto + Ã¡udio)")
    st.write("Envie uma **imagem**, **texto** e/ou **Ã¡udio (upload)** e clique em **Fazer previsÃ£o** para combinar as informaÃ§Ãµes.")

    # ğŸ“· Imagem opcional
    uploaded_img = st.file_uploader("ğŸ“· Envie uma imagem (opcional):", type=["jpg", "jpeg", "png"], key="predict_img")

    # ğŸ’¬ Texto opcional
    texto_input = st.text_area("ğŸ’¬ Texto descritivo (opcional):", key="predict_text")

    # ğŸ¤ Upload de Ã¡udio (opcional)
    st.subheader("ğŸ¤ Envie um Ã¡udio de voz (opcional)")
    uploaded_audio = st.file_uploader("ğŸ§ Arquivo de Ã¡udio (.wav, .mp3, .m4a)", type=["wav", "mp3", "m4a"])

    audio_text = ""
    if uploaded_audio:
        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp:
            tmp.write(uploaded_audio.read())
            tmp_path = tmp.name
        with st.spinner("ğŸ” Transcrevendo Ã¡udio..."):
            result = asr(tmp_path)
            audio_text = result["text"]
        st.success("âœ… TranscriÃ§Ã£o concluÃ­da!")
        st.text_area("ğŸ—£ï¸ Texto transcrito automaticamente:", value=audio_text, height=100, key="audio_text_area")

    # ğŸ§  GeraÃ§Ã£o da descriÃ§Ã£o da imagem
    desc_img = ""
    if uploaded_img:
        image = Image.open(uploaded_img).convert("RGB")
        st.image(image, caption="ğŸ“¸ Imagem enviada", use_container_width=True)
        with st.spinner("ğŸ” Gerando descriÃ§Ã£o automÃ¡tica da imagem..."):
            caption_en = captioner(image)[0]["generated_text"]
            desc_img = GoogleTranslator(source="en", target="pt").translate(caption_en)

    # ======================================================
    # ğŸ§© AnÃ¡lise separada de cada entrada
    # ======================================================
    st.markdown("---")
    st.subheader("ğŸ§© AnÃ¡lise separada de cada entrada")

    if desc_img:
        st.markdown("### ğŸ–¼ï¸ Imagem (descriÃ§Ã£o gerada)")
        st.write(desc_img)
        if st.session_state.vectorizer and st.session_state.modelo:
            X_img = st.session_state.vectorizer.transform([desc_img])
            pred_img = st.session_state.modelo.predict(X_img)[0]
            st.markdown(f"**PrevisÃ£o baseada apenas na imagem:** ğŸ§  {pred_img}")

    if audio_text:
        st.markdown("### ğŸ¤ Ãudio (transcriÃ§Ã£o reconhecida)")
        st.write(audio_text)
        if st.session_state.vectorizer and st.session_state.modelo:
            X_audio = st.session_state.vectorizer.transform([audio_text])
            pred_audio = st.session_state.modelo.predict(X_audio)[0]
            st.markdown(f"**PrevisÃ£o baseada apenas no Ã¡udio:** ğŸ§  {pred_audio}")

    if texto_input:
        st.markdown("### ğŸ’¬ Texto digitado")
        st.write(texto_input)
        if st.session_state.vectorizer and st.session_state.modelo:
            X_texto = st.session_state.vectorizer.transform([texto_input])
            pred_texto = st.session_state.modelo.predict(X_texto)[0]
            st.markdown(f"**PrevisÃ£o baseada apenas no texto:** ğŸ§  {pred_texto}")

    st.markdown("---")

    # ======================================================
    # ğŸ§© Combina todas as fontes de entrada
    # ======================================================
    entrada = f"{desc_img} {texto_input} {audio_text}".strip()
    st.text_area("ğŸ§© Entrada combinada:", value=entrada, height=120, key="entrada_combinada")

    # ======================================================
    # ğŸ”‘ Mostrar palavras reconhecidas pelo modelo
    # ======================================================
    if entrada and st.session_state.vectorizer:
        vocab = set(st.session_state.vectorizer.get_feature_names_out())
        tokenizer = st.session_state.vectorizer.build_analyzer()
        palavras_entrada = set(tokenizer(entrada.lower()))

        palavras_reconhecidas = palavras_entrada.intersection(vocab)
        palavras_nao_reconhecidas = palavras_entrada.difference(vocab)

        st.markdown("### ğŸ§  Palavras reconhecidas pelo modelo:")
        if palavras_reconhecidas:
            df_treino = pd.DataFrame({
                "texto": st.session_state.keywords,
                "categoria": st.session_state.categories
            })

            for categoria in df_treino["categoria"].unique():
                textos_cat = " ".join(df_treino[df_treino["categoria"] == categoria]["texto"]).lower()
                palavras_cat = set(tokenizer(textos_cat))
                palavras_match = palavras_cat.intersection(palavras_reconhecidas)
                if palavra
